{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c984ce-501a-4dec-8082-d480a51370a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from email import parser, policy\n",
    "from html import unescape\n",
    "\n",
    "import nltk\n",
    "import pandas\n",
    "import urlextract\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics, preprocessing, naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from email.parser import BytesParser\n",
    "\n",
    "import joblib\n",
    "# import sys\n",
    "# print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10364db4-6957-42d3-882c-fbf879462fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "INDEX_PATH = os.path.join('trec07p', 'test', 'index')  # 先使用较小的数据集进行训练\n",
    "DATA_PATH = os.path.join('trec07p', 'data')  # 数据文件夹路径\n",
    "labels = []\n",
    "filenames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f432838d-d027-4813-aaa0-dd443733d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将delay中的标签和对应的文件名保存\n",
    "def create_dataset(index_path):\n",
    "    with open(index_path) as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.split(' ')\n",
    "            labels.append(line[0])\n",
    "            filenames.append(line[1].strip('\\n').split('/')[-1])\n",
    "            \n",
    "create_dataset(INDEX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc5fd65-465d-4041-86f6-aa382c1cfb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载delay中索引的文件内容\n",
    "def load_email(filename, file_path):\n",
    "    with open(os.path.join(file_path, filename), 'rb') as f:\n",
    "        return parser.BytesParser(policy=policy.default).parse(f)\n",
    "\n",
    "raw_emails = [load_email(name, DATA_PATH) for name in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0a7529-ca32-4fef-ad66-b3582bc088f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Billy, \n",
      "\n",
      "it was really fun going out the other night \n",
      "and talking, while we were out you said that you felt\n",
      "insecure about your manhood, I noticed in the toilets\n",
      "you were quite small in that area : ) , but not to \n",
      "worry.. that website that I was telling you about is \n",
      "my secret weapon to an extra 3 inches, trust me.. girls\n",
      "love bigger ones, I've had 5 times as many chicks \n",
      "since I used these pills a year ago. The package I used\n",
      "was the 6 month supply one,  and its worth every \n",
      "cent and more.. the website is http://ctmay.com \n",
      "Ring me on the weekend and we will go out and drink \n",
      "again and let you know some more secrets : ).\n",
      "Later dude, Brad\n"
     ]
    }
   ],
   "source": [
    "print(raw_emails[3].get_content().strip())  # 打印邮件文本内容，注意这里输出内容不一定是正确的，只有当邮件为文本类型，才能输出；不能正确输出说明邮件是多部份的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3319975c-c47d-4f1f-b396-6518481e52be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 构造函数获取邮件的结构类型及其计数\n",
    "\n",
    "# 确定每封电子邮件的结构类型\n",
    "def get_email_structure(email):\n",
    "    if isinstance(email, str): # 字符串直接返回\n",
    "        return email\n",
    "    payload = email.get_payload() # 提取email的主体部分\n",
    "    if isinstance(payload, list): # 如果是列表，说明该邮件为多部份\n",
    "        return 'multipart({})'.format(', '.join([get_email_structure(sub_email) for sub_email in payload]))\n",
    "        # 如果有两个子部分，一个是 text/plain，另一个是 text/html，那么最终的结果将是 'multipart(text/plain, text/html)'\n",
    "    else: # 否则一般是text/plain或text/html\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bcb24e-db82-4fd7-8ee1-871789c85fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计一组电子邮件中各种结构类型的出现次数\n",
    "def structures_counter(emails):\n",
    "    structures = Counter() # 字典类型\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273afc1f-8f21-481a-b0b4-4bba67fa1445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('text/plain', 411), ('multipart(text/plain, text/html)', 206), ('text/html', 139), ('multipart(multipart(text/plain, text/html), image/gif)', 88), ('multipart(multipart(text/plain, text/html), image/jpeg)', 65), ('multipart(text/html)', 32), ('multipart(text/html, image/gif)', 20), ('multipart(text/plain)', 17), ('multipart(text/plain, application/x-msdownload)', 9), ('multipart(multipart(text/plain, text/html), image/png)', 3), ('multipart(text/plain, application/pgp-signature)', 3), ('multipart(text/plain, multipart(text/plain), text/plain)', 1), ('multipart(text/plain, text/plain)', 1), ('multipart(text/plain, application/octet-stream)', 1), ('multipart(text/html, image/jpeg)', 1), ('multipart(text/plain, text/x-patch)', 1), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/jpeg, application/octet-stream)', 1), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/gif, image/gif, image/jpeg, image/gif, application/octet-stream, image/gif, image/jpeg, image/gif)', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n这对于分析电子邮件数据集的结构分布非常有用，可以帮助我们理解数据集中最常见的电子邮件类型，从而为进一步的数据处理和特征工程提供信息。\\n例如，如果多数邮件都是纯文本类型，那么我们可能会专注于文本内容的分析；如果有大量的多部分邮件，我们可能需要考虑如何处理嵌入的图片或附件。\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(structures_counter(raw_emails).most_common())  # 显示邮件包含的类型\n",
    "\"\"\"\n",
    "这对于分析电子邮件数据集的结构分布非常有用，可以帮助我们理解数据集中最常见的电子邮件类型，从而为进一步的数据处理和特征工程提供信息。\n",
    "例如，如果多数邮件都是纯文本类型，那么我们可能会专注于文本内容的分析；如果有大量的多部分邮件，我们可能需要考虑如何处理嵌入的图片或附件。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab30254-677e-4b2d-ad4d-514453ec64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将原始的电子邮件内容转换为更适合文本分析和机器学习模型训练的格式\n",
    "\n",
    "# 将HTML内容转换为纯文本，同时替换为相应的关键词\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub(r'<[aA]\\s.*?>', 'HYPERLINK', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub(r'<img\\s.*?>', 'IMAGE', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7a6f90-4ff2-4551-b44d-769433df9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于从电子邮件中提取文本内容\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    # walk()打印出一封具有多部分结构之信息的每个部分的MIME类型\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if ctype not in ('text/plain', 'text/html'):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except LookupError:\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f06a85b-6d7a-4e9b-964f-a6e3088df8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\86180\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下载 stopwords 资源\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86aa8d7d-01a5-494e-8dc3-9f89e0bd6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词\n",
    "stopwords_list = stopwords.words('english')  # 英文停用词列表\n",
    "token = nltk.stem.SnowballStemmer('english')  # 提取词干，词干提取器对象，用于将单词还原为基本形式或词干。例如，将“running”还原为“run”。\n",
    "\n",
    "# 将所有小写英文字母添加到停用词列表\n",
    "for single in range(97, 123):\n",
    "    stopwords_list.append(chr(single))\n",
    "    \n",
    "extractor = urlextract.URLExtract() # 创建了一个URL提取器对象，用于从文本中找出URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66259473-6266-4c3a-b2b7-63c2652fd23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将电子邮件文本转换为一个清洗和标准化的单词列表\n",
    "def word_split(email):\n",
    "    text = email_to_text(email) or ' '\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text, flags=re.M) # 使用正则表达式替换文本中的所有非字母数字字符为单个空格\n",
    "    urls = list(set(extractor.find_urls(text))) # 一个去重的URL列表\n",
    "    urls.sort(key=lambda item: len(item), reverse=True) # 将找到的URL按长度降序排序\n",
    "    for url in urls:\n",
    "        text = text.replace(url, \"URL\") # 将文本中的所有URL替换为特征词“URL”\n",
    "    text = re.sub(r'\\d+(?:\\.\\d*[eE]\\d+)?', 'NUMBER', text) # 使用正则表达式将文本中的所有数字替换为字符串“NUMBER”\n",
    "    content = list(nltk.word_tokenize(text)) # 使用NLTK的 word_tokenize 函数将文本分割成单词列表\n",
    "    all_words = []\n",
    "    for word in content:\n",
    "        if word not in stopwords_list:\n",
    "            word = token.stem(word)\n",
    "            all_words.append(word)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70ee3ff8-fa1d-4a09-b33c-e88111fda395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\86180\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下载 punkt 资源\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deabd5d7-d66e-4014-8f73-1a9126f7f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emails = [word_split(data) for data in raw_emails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c2aa6f8-b472-4a65-8477-bf3ea0946f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'updat', 'gulus', 'check', 'mirror', 'seem', 'littl', 'typo', 'debian', 'readm', 'file', 'exampl', 'http', 'gulus', 'usherbrook', 'ca', 'debian', 'readm', 'ftp', 'ftp', 'fr', 'debian', 'org', 'debian', 'readm', 'test', 'lenni', 'access', 'releas', 'dist', 'test', 'current', 'test', 'develop', 'snapshot', 'name', 'etch', 'packag', 'test', 'unstabl', 'pass', 'autom', 'test', 'propog', 'releas', 'etch', 'replac', 'lenni', 'like', 'readm', 'html', 'yan', 'morin', 'consult', 'en', 'logiciel', 'libr', 'yan', 'morin', 'savoirfairelinux', 'com', 'number', 'number', 'number', 'unsubscrib', 'email', 'debian', 'mirror', 'request', 'list', 'debian', 'org', 'subject', 'unsubscrib', 'troubl', 'contact', 'listmast', 'list', 'debian', 'org']\n"
     ]
    }
   ],
   "source": [
    "print(all_emails[1])  # 查看分词结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e3053fb-138a-42dc-9ea7-78b509b0434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征提取\n",
    "# 创建一个dataframe，列名为text和label\n",
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = all_emails\n",
    "trainDF['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c677620-f379-4496-9c93-3982edbe6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集分为训练集和测试集，以便模型能在训练集上学习并在测试集上验证其性能\n",
    "# sklearn.model_selection.train_test_split\n",
    "train_data, test_data, train_label, test_label = train_test_split(trainDF['text'],trainDF['label'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e4ecb6c-995d-4d95-b5ee-6d74b1ce2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label编码为目标变量,即从字符串转为一个数字\n",
    "# sklearn.preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_label = encoder.fit_transform(train_label)\n",
    "test_label = encoder.fit_transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "314dfe8d-6b4e-4194-b832-1785a7ccf695",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['text'] = [' '.join(email) for email in all_emails]\n",
    "train_data = [' '.join(doc) for doc in train_data]\n",
    "test_data = [' '.join(doc) for doc in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c85af89-fb06-4694-8225-096c5cb5bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 计数特征向量\n",
    "# sklearn.feature_extraction.text.CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "count_vect.fit(trainDF['text'])\n",
    "xtrain_count = count_vect.transform(train_data)  # 训练集特征向量\n",
    "xtest_count = count_vect.transform(test_data)  # 测试集特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59da7d6c-c0a1-4f37-b6e6-430d608173a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.98 0.9818181818181817 0.98 0.9803496081977094\n"
     ]
    }
   ],
   "source": [
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(xtrain_count, train_label)\n",
    "# 使用测试集的特征向量进行预测\n",
    "predictions = model.predict(xtest_count)\n",
    "# 使用测试集的标签来计算评估指标\n",
    "accuracy = metrics.accuracy_score(test_label, predictions)\n",
    "precision = metrics.precision_score(test_label, predictions, average='weighted')\n",
    "recall = metrics.recall_score(test_label, predictions, average='weighted')\n",
    "f1_score = metrics.f1_score(test_label, predictions, average='weighted')\n",
    "print(\"NB, Count Vectors: \", accuracy, precision, recall, f1_score)\n",
    "# 保存模型\n",
    "joblib.dump(model, 'NB_model.pkl')\n",
    "# 保存向量化器\n",
    "joblib.dump(count_vect, 'NB_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0d3a6-3d13-416e-8fca-db9b106ae708",
   "metadata": {},
   "source": [
    "### 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4511800d-fec6-44f0-b825-393a9335cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "# 加载模型和向量化器\n",
    "model = joblib.load('BernliNB_model.pkl')\n",
    "vectorizer = joblib.load('BernliNB_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fee881b-978f-4068-90ad-701ee34d9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历文件夹中的邮件\n",
    "emails, predictions = [], []\n",
    "for root, dirs, files in os.walk('trec07p/data'):\n",
    "    for file in files:\n",
    "        with open(os.path.join(root, file), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            email_content = f.read()\n",
    "        emails.append(email_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b133603-7da9-462e-a9a4-bf32edda4975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "垃圾邮件占比: 53.02%\n",
      "非垃圾邮件占比: 46.98%\n"
     ]
    }
   ],
   "source": [
    "# 特征提取\n",
    "email_features = vectorizer.transform(emails)\n",
    "# 模型预测\n",
    "# predictions = model.predict(email_features)\n",
    "import numpy as np\n",
    "\n",
    "# 获取模型预测的概率\n",
    "probabilities = model.predict_proba(email_features)\n",
    "\n",
    "# 设置新的阈值\n",
    "threshold = 0.58\n",
    "predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "spam_count = sum(predictions)\n",
    "ham_count = len(predictions) - spam_count\n",
    "\n",
    "spam_ratio = spam_count / len(predictions)\n",
    "ham_ratio = ham_count / len(predictions)\n",
    "\n",
    "print(f'垃圾邮件占比: {spam_ratio:.2%}')\n",
    "print(f'非垃圾邮件占比: {ham_ratio:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f695772-7d78-4038-b7b8-07aabeaf5db2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This BernoulliNB instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m email_features \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(emails)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 模型预测\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43memail_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 计算垃圾邮件和非垃圾邮件的数量\u001b[39;00m\n\u001b[0;32m      6\u001b[0m spam_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(predictions)\n",
      "File \u001b[1;32mC:\\ANACONDA\\envs\\py38\\lib\\site-packages\\sklearn\\naive_bayes.py:100\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    Perform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m        Predicted target values for X.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m    102\u001b[0m     jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n",
      "File \u001b[1;32mC:\\ANACONDA\\envs\\py38\\lib\\site-packages\\sklearn\\utils\\validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This BernoulliNB instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# 特征提取\n",
    "email_features = vectorizer.transform(emails)\n",
    "# 模型预测\n",
    "predictions = model.predict(email_features)\n",
    "# 计算垃圾邮件和非垃圾邮件的数量\n",
    "spam_count = sum(predictions)\n",
    "ham_count = len(predictions) - spam_count\n",
    "\n",
    "# 计算占比\n",
    "spam_ratio = spam_count / len(predictions)\n",
    "ham_ratio = ham_count / len(predictions)\n",
    "\n",
    "print(f'垃圾邮件占比: {spam_ratio:.2%}')\n",
    "print(f'非垃圾邮件占比: {ham_ratio:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1cb131d-985d-41be-88c4-842dc45ed6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "垃圾邮件占比: 66.56%\n",
      "非垃圾邮件占比: 33.44%\n"
     ]
    }
   ],
   "source": [
    "index_path = 'trec07p/full/index'\n",
    "# 初始化计数器\n",
    "spam_count = 0\n",
    "ham_count = 0\n",
    "\n",
    "with open(index_path, 'r') as file:\n",
    "    for line in file:\n",
    "        if 'spam' in line:\n",
    "            spam_count += 1\n",
    "        elif 'ham' in line:\n",
    "            ham_count += 1\n",
    "\n",
    "# 计算总邮件数量\n",
    "total_emails = spam_count + ham_count\n",
    "\n",
    "# 计算占比\n",
    "spam_percentage = (spam_count / total_emails) * 100\n",
    "ham_percentage = (ham_count / total_emails) * 100\n",
    "\n",
    "# 输出结果\n",
    "print(f\"垃圾邮件占比: {spam_percentage:.2f}%\")\n",
    "print(f\"非垃圾邮件占比: {ham_percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38kernel",
   "language": "python",
   "name": "py38-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
