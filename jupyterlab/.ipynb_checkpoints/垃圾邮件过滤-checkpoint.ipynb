{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13c477c-c482-4626-9423-516710383645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from email import parser, policy\n",
    "from html import unescape\n",
    "\n",
    "import nltk\n",
    "import pandas\n",
    "import urlextract\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics, preprocessing, naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from email.parser import BytesParser\n",
    "# import sys\n",
    "# print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cf93e0-b06d-4413-9cd5-fb76dd30cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "INDEX_PATH = os.path.join('trec07p', 'delay', 'index')  # 先使用较小的数据集进行训练\n",
    "DATA_PATH = os.path.join('trec07p', 'data')  # 数据文件夹路径\n",
    "labels = []\n",
    "filenames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cdf8616-3473-4ad7-9076-d7c1c8b3f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(index_path):\n",
    "    with open(index_path) as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.split(' ')\n",
    "            labels.append(line[0])\n",
    "            filenames.append(line[1].strip('\\n').split('/')[-1])\n",
    "            \n",
    "create_dataset(INDEX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19fad2d-ac67-4279-8de1-66edf6053323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_email(filename, file_path):\n",
    "    with open(os.path.join(file_path, filename), 'rb') as f:\n",
    "        return parser.BytesParser(policy=policy.default).parse(f)\n",
    "\n",
    "raw_emails = [load_email(name, DATA_PATH) for name in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07c81b6-737a-47fd-9aec-ecc8e7e78d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Billy, \n",
      "\n",
      "it was really fun going out the other night \n",
      "and talking, while we were out you said that you felt\n",
      "insecure about your manhood, I noticed in the toilets\n",
      "you were quite small in that area : ) , but not to \n",
      "worry.. that website that I was telling you about is \n",
      "my secret weapon to an extra 3 inches, trust me.. girls\n",
      "love bigger ones, I've had 5 times as many chicks \n",
      "since I used these pills a year ago. The package I used\n",
      "was the 6 month supply one,  and its worth every \n",
      "cent and more.. the website is http://ctmay.com \n",
      "Ring me on the weekend and we will go out and drink \n",
      "again and let you know some more secrets : ).\n",
      "Later dude, Brad\n"
     ]
    }
   ],
   "source": [
    "print(raw_emails[3].get_content().strip())  # 打印邮件文本内容，注意这里输出内容不一定是正确的，只有当邮件为文本类型，才能输出；不能正确输出说明邮件是多部份的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfdc1ec9-d079-41dd-acfa-a5a42acb83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 构造函数获取邮件的结构类型及其计数\n",
    "\n",
    "# 确定每封电子邮件的结构类型\n",
    "def get_email_structure(email):\n",
    "    if isinstance(email, str): # 字符串直接返回\n",
    "        return email\n",
    "    payload = email.get_payload() # 提取email的主体部分\n",
    "    if isinstance(payload, list): # 如果是列表，说明该邮件为多部份\n",
    "        return 'multipart({})'.format(', '.join([get_email_structure(sub_email) for sub_email in payload]))\n",
    "        # 如果有两个子部分，一个是 text/plain，另一个是 text/html，那么最终的结果将是 'multipart(text/plain, text/html)'\n",
    "    else: # 否则一般是text/plain或text/html\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ba7aa7-7dd5-43ba-a292-7f2bd72607e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计一组电子邮件中各种结构类型的出现次数\n",
    "def structures_counter(emails):\n",
    "    structures = Counter() # 字典类型\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "942a34ca-566c-4231-8a33-3f3e9eaa795d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('text/plain', 29989), ('multipart(text/plain, text/html)', 17496), ('text/html', 11978), ('multipart(multipart(text/plain, text/html), image/gif)', 5066), ('multipart(text/html)', 3741), ('multipart(multipart(text/plain, text/html), image/jpeg)', 2510), ('multipart(text/html, image/gif)', 1021), ('multipart(text/plain)', 682), ('multipart(text/plain, application/pgp-signature)', 595), ('multipart(text/plain, text/plain)', 398), ('multipart(multipart(text/plain, text/html), image/png)', 240), ('multipart(multipart(text/plain, text/html))', 151), ('multipart(multipart(text/plain, text/html), text/plain)', 135), ('multipart(text/html, text/plain, image/png)', 122), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/jpeg, application/octet-stream)', 116), ('multipart(text/plain charset=us-ascii, text/html)', 108), ('multipart(text/plain, application/octet-stream)', 75), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/gif, image/gif, application/octet-stream)', 60), ('multipart(text/plain, text/x-patch)', 49), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/jpeg, image/jpeg)', 49), ('multipart(text/plain, text/x-diff)', 46), ('multipart(multipart(multipart(text/plain, text/html), image/gif), text/plain)', 45), ('multipart(text/plain, application/pdf)', 44), ('multipart(text/plain, multipart(text/plain, text/plain), multipart(text/html))', 40), ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(multipart(text/plain, text/html), image/gif)))', 38), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/gif, image/gif, image/jpeg, image/gif, application/octet-stream, image/gif, image/jpeg, image/gif)', 35), ('multipart(multipart(text/plain, application/pgp-signature), text/plain)', 34), ('multipart(multipart(text/plain, text/html), image/jpg)', 33), ('multipart(text/plain, text/plain, text/plain)', 30), ('multipart(text/plain, text/html, image/gif)', 29), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/gif, image/gif)', 27), ('multipart(text/html, image/jpeg)', 23), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif)', 20), ('multipart(multipart(text/html))', 18), ('multipart(multipart(text/plain, text/plain), application/pgp-signature)', 17), ('multipart(multipart(text/plain, text/x-patch), application/pgp-signature)', 16), ('multipart(multipart(text/html), image/gif)', 16), ('multipart(text/plain, application/x-msdownload)', 15), ('multipart(multipart(text/plain, text/html), application/octet-stream)', 13), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/jpeg, image/gif)', 12), ('multipart(multipart(text/plain, text/html), image/gif, image/gif)', 12), ('multipart(multipart(multipart(text/plain, text/html), image/jpeg), text/plain)', 11), ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)', 10), ('multipart(multipart(text/plain))', 10), ('multipart(multipart(text/plain, application/x-pkcs7-signature), text/plain)', 9), ('multipart(text/plain, multipart(text/html))', 9), ('multipart(text/plain, application/x-pkcs7-signature)', 9), ('multipart(multipart(text/plain, text/x-diff), application/pgp-signature)', 9), ('multipart(text/plain, text/x-patch, application/pgp-signature)', 8), ('multipart(multipart(text/html, image/gif), application/octet-stream)', 8), ('multipart(text/plain, application/octet-stream, application/octet-stream)', 8), ('multipart(multipart(text/plain), text/plain)', 7), ('multipart(multipart(text/plain), application/octet-stream)', 7), ('multipart(text/plain, text/x-patch, text/plain)', 7), ('multipart(text/html, application/octet-stream)', 6), ('multipart(text/html, image/png)', 6), ('multipart(text/plain, text/html, text/plain)', 6), ('multipart(text/plain, text/x-patch, text/x-patch)', 5), ('multipart(text/plain, multipart(text/plain))', 5), ('multipart(text/html, text/html)', 5), ('multipart(text/plain, multipart(text/plain, text/plain), multipart(text/plain))', 5), ('multipart(text/plain, text/plain, text/plain, text/plain)', 4), ('multipart(multipart(text/html), image/jpeg)', 4), ('multipart(text/plain, application/pdf, text/plain)', 4), ('multipart(text/html, image/jpeg, image/jpeg, image/jpeg)', 4), ('multipart(text/plain, multipart(text/html, image/gif))', 4), ('multipart(text/plain, multipart(text/plain), text/plain)', 3), ('multipart(multipart(text/plain, text/html), application/pgp-signature)', 3), ('multipart(text/plain, text/x-patch, application/octet-stream)', 3), ('multipart(multipart(text/plain, multipart(text/html)))', 3), ('multipart(multipart(text/plain, text/html), image/jpeg, image/gif)', 3), ('multipart(text/plain, text/x-diff, text/plain, text/plain)', 3), ('multipart(multipart(text/plain, text/html), image/gif, image/jpeg, image/gif)', 3), ('multipart(text/plain, text/x-log, text/plain)', 2), ('multipart(text/plain, image/png, text/plain)', 2), ('multipart(text/plain, multipart(text/plain), multipart(text/html))', 2), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/jpeg)', 2), ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/gif)', 2), ('multipart(text/plain, text/x-diff, text/plain)', 2), ('multipart(text/plain, text/plain, application/pgp-signature)', 2), ('multipart(multipart(text/plain, text/html), image/jpeg, image/gif, image/gif, image/jpeg, image/jpeg, image/jpeg, image/jpeg)', 2), ('multipart(multipart(multipart(text/plain, text/x-diff, text/x-diff, text/x-diff), application/pgp-signature), text/plain)', 2), ('multipart(multipart(text/plain, text/html), application/octet-stream, application/octet-stream)', 2), ('multipart(multipart(text/html), text/plain)', 2), ('multipart(text/plain, text/x-log, text/x-log, text/plain)', 2), ('multipart/alternative', 2), ('multipart(text/plain, plain/text)', 1), ('multipart(multipart(text/plain, text/x-patch, text/x-patch), application/pgp-signature)', 1), ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, text/html)))', 1), ('multipart(text/html, text/richtext)', 1), ('multipart(text/plain, text/x-diff, text/x-diff)', 1), ('multipart(multipart(text/plain, text/html, image/gif))', 1), ('multipart(multipart(text/plain, application/x-bzip), application/pgp-signature)', 1), ('multipart(multipart(multipart(text/plain)))', 1), ('multipart(text/plain, text/x-patch, text/x-patch, text/x-patch, text/x-patch)', 1), ('multipart(text/plain, text/plain, text/plain, text/plain, text/plain, text/plain, text/plain, text/plain, text/plain, text/plain)', 1), ('multipart(text/plain, application/octet-stream, text/plain)', 1), ('multipart(text/html, multipart(text/html))', 1), ('multipart(text/plain, text/html, application/octet-stream)', 1), ('multipart(text/plain, application/x-gzip, application/pgp-signature)', 1), ('multipart(text/plain, text/x-vcard, text/plain)', 1), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, application/octet-stream)', 1), ('multipart(multipart(text/plain, multipart(text/plain), multipart(text/html)), text/plain)', 1), ('multipart(text/plain, text/x-patch, text/troff)', 1), ('multipart(multipart(multipart(text/plain, text/x-diff, text/x-diff, text/x-diff, text/x-diff), application/pgp-signature), text/plain)', 1), ('multipart(text/plain, application/x-gzip)', 1), ('multipart(text/plain, image/tiff, text/plain)', 1), ('multipart(multipart(text/plain, text/html), application/octet-stream, application/octet-stream, application/octet-stream)', 1), ('multipart(text/plain, text/x-csrc, text/plain)', 1), ('multipart(text/plain, text/x-csrc, text/x-chdr, text/x-patch, application/pgp-signature)', 1), ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/jpeg)', 1), ('multipart(multipart(text/plain, text/x-csrc, application/x-perl, application/octet-stream), application/pgp-signature)', 1), ('multipart(multipart(text/plain, text/x-csrc, application/octet-stream, application/octet-stream), application/pgp-signature)', 1), ('multipart(multipart(text/plain, text/html), image/jpeg, text/plain)', 1), ('multipart(text/plain, image/jpeg, text/plain)', 1), ('multipart(multipart(text/plain, text/x-csrc), application/pgp-signature)', 1), ('multipart(text/plain, application/zip)', 1), ('multipart(text/plain, multipart(text/plain), multipart(text/plain))', 1), ('multipart(multipart(multipart(text/plain, text/plain)), text/plain)', 1), ('multipart(text/plain, application/pdf, text/plain, text/plain)', 1), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/gif, image/gif, image/gif, application/octet-stream, image/gif, image/gif, image/jpeg, image/jpeg)', 1), ('multipart(multipart(text/html, image/png, image/png), text/plain)', 1), ('multipart(text/plain, text/x-perl, text/plain)', 1), ('multipart(multipart(multipart(text/plain, text/x-diff, text/x-diff, text/x-diff, text/x-diff, text/x-diff, text/x-diff, text/x-diff, text/x-diff, text/x-diff, text/x-diff, text/x-diff, text/x-diff), application/pgp-signature), text/plain)', 1), ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)', 1), ('multipart(text/plain, multipart(multipart(text/plain, image/jpeg)))', 1), ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(multipart(text/plain, text/html), image/jpeg)))', 1), ('multipart(multipart(text/plain, text/x-chdr), application/pgp-signature)', 1), ('multipart(multipart(text/plain), image/gif)', 1), ('multipart(text/html, application/octet-stream, application/octet-stream)', 1), ('multipart(text/plain, application/x-perl, text/plain)', 1), ('multipart/alternreturn-path: <accounting@aaawnca.com>', 1), ('multipart(text/plain, text/plain, text/plain, text/plain, text/plain, text/plain, text/plain)', 1), ('multipart(text/plain, multipart(application/applefile, text/plain), text/plain)', 1), ('multipart(multipart(text/plain, text/x-objcsrc, text/plain), application/pgp-signature)', 1), ('multipart(text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html, text/html)', 1), ('multipart(multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(multipart(text/plain, text/html), image/jpeg))), text/plain)', 1), ('multipart(text/plain, application/x-tar)', 1), ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/gif)', 1), ('multipart(text/plain, application/octet-stream, application/octet-stream, application/octet-stream, application/octet-stream)', 1), ('multipart(text/plain, text/plain, application/octet-stream)', 1), ('multipart(multipart(multipart(text/plain, text/plain), application/pgp-signature), text/plain)', 1), ('text/', 1), ('multipart(multipart(text/plain, text/html), application/octet-stream, text/plain)', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n这对于分析电子邮件数据集的结构分布非常有用，可以帮助我们理解数据集中最常见的电子邮件类型，从而为进一步的数据处理和特征工程提供信息。\\n例如，如果多数邮件都是纯文本类型，那么我们可能会专注于文本内容的分析；如果有大量的多部分邮件，我们可能需要考虑如何处理嵌入的图片或附件。\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(structures_counter(raw_emails).most_common())  # 显示邮件包含的类型\n",
    "\"\"\"\n",
    "这对于分析电子邮件数据集的结构分布非常有用，可以帮助我们理解数据集中最常见的电子邮件类型，从而为进一步的数据处理和特征工程提供信息。\n",
    "例如，如果多数邮件都是纯文本类型，那么我们可能会专注于文本内容的分析；如果有大量的多部分邮件，我们可能需要考虑如何处理嵌入的图片或附件。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "984c80da-37bd-4bd5-bc36-dd162ce62ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将原始的电子邮件内容转换为更适合文本分析和机器学习模型训练的格式\n",
    "\n",
    "# 将HTML内容转换为纯文本\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub(r'<[aA]\\s.*?>', 'HYPERLINK', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub(r'<img\\s.*?>', 'IMAGE', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e824973-947e-40a1-b47b-be4b4a704aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于从电子邮件中提取文本内容\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    # walk()打印出一封具有多部分结构之信息的每个部分的MIME类型\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if ctype not in ('text/plain', 'text/html'):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except LookupError:\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488a80eb-9f58-419e-8fa8-22ef7eac6547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\86180\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下载 stopwords 资源\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6eeb2f7-d2e7-44fe-9c3e-16a0b9a154f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词\n",
    "stopwords_list = stopwords.words('english')  # 英文停用词列表\n",
    "token = nltk.stem.SnowballStemmer('english')  # 提取词干，词干提取器对象，用于将单词还原为基本形式或词干。例如，将“running”还原为“run”。\n",
    "\n",
    "# 将所有小写英文字母添加到停用词列表\n",
    "for single in range(97, 123):\n",
    "    stopwords_list.append(chr(single))\n",
    "    \n",
    "extractor = urlextract.URLExtract() # 创建了一个URL提取器对象，用于从文本中找出URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a7736d2-7741-415a-9f4b-bdd8dcc7c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将电子邮件文本转换为一个清洗和标准化的单词列表\n",
    "def word_split(email):\n",
    "    text = email_to_text(email) or ' '\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text, flags=re.M) # 使用正则表达式替换文本中的所有非字母数字字符为单个空格\n",
    "    urls = list(set(extractor.find_urls(text))) # 一个去重的URL列表\n",
    "    urls.sort(key=lambda item: len(item), reverse=True) # 将找到的URL按长度降序排序\n",
    "    for url in urls:\n",
    "        text = text.replace(url, \"URL\") # 将文本中的所有URL替换为特征词“URL”\n",
    "    text = re.sub(r'\\d+(?:\\.\\d*[eE]\\d+)?', 'NUMBER', text) # 使用正则表达式将文本中的所有数字替换为字符串“NUMBER”\n",
    "    content = list(nltk.word_tokenize(text)) # 使用NLTK的 word_tokenize 函数将文本分割成单词列表\n",
    "    all_words = []\n",
    "    for word in content:\n",
    "        if word not in stopwords_list:\n",
    "            word = token.stem(word)\n",
    "            all_words.append(word)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78fb3b7a-36a9-4ad3-bbc0-89979af1a77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\86180\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下载 punkt 资源\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25150194-5430-49a1-ba70-a6df5dd85fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feel', 'pressur', 'perform', 'rise', 'occas', 'hyperlinktri', 'viagra', 'anxieti', 'thing', 'past', 'back', 'old', 'self']\n"
     ]
    }
   ],
   "source": [
    "all_emails = [word_split(data) for data in raw_emails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21deacbd-bedb-43ba-8627-19bb0555c4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'updat', 'gulus', 'check', 'mirror', 'seem', 'littl', 'typo', 'debian', 'readm', 'file', 'exampl', 'http', 'gulus', 'usherbrook', 'ca', 'debian', 'readm', 'ftp', 'ftp', 'fr', 'debian', 'org', 'debian', 'readm', 'test', 'lenni', 'access', 'releas', 'dist', 'test', 'current', 'test', 'develop', 'snapshot', 'name', 'etch', 'packag', 'test', 'unstabl', 'pass', 'autom', 'test', 'propog', 'releas', 'etch', 'replac', 'lenni', 'like', 'readm', 'html', 'yan', 'morin', 'consult', 'en', 'logiciel', 'libr', 'yan', 'morin', 'savoirfairelinux', 'com', 'number', 'number', 'number', 'unsubscrib', 'email', 'debian', 'mirror', 'request', 'list', 'debian', 'org', 'subject', 'unsubscrib', 'troubl', 'contact', 'listmast', 'list', 'debian', 'org']\n"
     ]
    }
   ],
   "source": [
    "print(all_emails[1])  # 查看分词结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bfc6548-cca5-472a-ac32-feff430db896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征提取\n",
    "# 创建一个dataframe，列名为text和label\n",
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = all_emails\n",
    "trainDF['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "064de1ef-8395-412c-935a-0cdcbf0f44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集分为训练集和测试集，以便模型能在训练集上学习并在测试集上验证其性能\n",
    "# sklearn.model_selection.train_test_split\n",
    "train_data, test_data, train_label, test_label = train_test_split(trainDF['text'],trainDF['label'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb452a63-253f-4fbb-9284-ae6bd1033af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label编码为目标变量,即从字符串转为一个数字\n",
    "# sklearn.preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_label = encoder.fit_transform(train_label)\n",
    "test_label = encoder.fit_transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d809634-0dc0-4bd0-a07e-51dc23a74297",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['text'] = [' '.join(email) for email in all_emails]\n",
    "train_data = [' '.join(doc) for doc in train_data]\n",
    "test_data = [' '.join(doc) for doc in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4730d1f-9b83-4750-a3ae-7887fbbccba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 计数特征向量\n",
    "# sklearn.feature_extraction.text.CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "count_vect.fit(trainDF['text'])\n",
    "xtrain_count = count_vect.transform(train_data)  # 训练集特征向量\n",
    "xtest_count = count_vect.transform(test_data)  # 测试集特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbcb3418-e597-4004-9fa8-90d8f3f958db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类任务\n",
    "# 创建分类器\n",
    "# sklearn.metrics\n",
    "def train_model(classifier, train_feature, train_label, test_feature, test_label):\n",
    "    classifier.fit(train_feature, train_label)\n",
    "    prediction = classifier.predict(test_feature)\n",
    "    acc = metrics.accuracy_score(prediction, test_label)\n",
    "    prec = metrics.precision_score(test_label, prediction, average='weighted')\n",
    "    rec = metrics.recall_score(test_label, prediction, average='weighted')\n",
    "    f1 = metrics.f1_score(test_label, prediction, average='weighted')\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecbfab3a-94c4-4e88-a9dd-09ad4f5e9344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.813312118801379 0.8362915257721493 0.813312118801379 0.8178264288284937\n"
     ]
    }
   ],
   "source": [
    "# 5.1 朴素贝叶斯多项式模型\n",
    "# 5.1.1 计数特征向量\n",
    "# Sklearn.naive_bayes\n",
    "# accuracy, precision, recall, f1_socre = train_model(naive_bayes.MultinomialNB(), xtrain_count, xtest_count)\n",
    "# print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy, precision, recall, f1_score = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_label, xtest_count, test_label)\n",
    "print(\"MulNB, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30ff7c99-850e-45f3-a454-0d857ee4cf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernliNB, Count Vectors:  0.8071068682047202 0.8443822926474205 0.8071068682047202 0.8178264288284937\n"
     ]
    }
   ],
   "source": [
    "# 5.2 朴素贝叶斯伯努利模型\n",
    "# 5.2.1 计数特征向量\n",
    "accuracy, precision, recall, f1_socre = train_model(naive_bayes.BernoulliNB(), xtrain_count, train_label, xtest_count, test_label)\n",
    "print(\"BernliNB, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cd4cb45-85fd-48e0-a027-1aa273385b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC, Count Vectors:  0.8853884911164147 0.8916991038245062 0.8853884911164147 0.8178264288284937\n"
     ]
    }
   ],
   "source": [
    "# 5.3 SVM\n",
    "# 5.3.1 计数特征向量 sklearn.svm\n",
    "from sklearn import svm\n",
    "accuracy, precision, recall, f1_socre = train_model(svm.SVC(), xtrain_count, train_label, xtest_count, test_label)\n",
    "print(\"SVC, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea6b84e7-da2f-4ac5-9af1-41df5586d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFCF, Count Vectors:  0.916839034738796 0.9145267205462085 0.916839034738796 0.8178264288284937\n"
     ]
    }
   ],
   "source": [
    "# 5.4 随机森林 sklearn.ensemble\n",
    "# 5.4.1 计数特征向量\n",
    "from sklearn import ensemble\n",
    "accuracy, precision, recall, f1_socre = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_label, xtest_count, test_label)\n",
    "print(\"RFCF, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "127afae1-7ca5-44f6-ad29-0a69e0e8667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN, Count Vectors:  0.8784407319013524 0.8743603997243775 0.8784407319013524 0.8178264288284937\n"
     ]
    }
   ],
   "source": [
    "# 5.5 KNN sklearn.neighbors\n",
    "# 5.5.1 计数特征向量\n",
    "from sklearn import neighbors\n",
    "accuracy, precision, recall, f1_socre = train_model(neighbors.KNeighborsClassifier(), xtrain_count, train_label, xtest_count, test_label)\n",
    "print(\"KNN, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f665c7f-387c-4911-b346-209c314d6fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 TF-IDF特征向量\n",
    "# sklearn.feature_extraction.text.TfidfVectorizer\n",
    "# 4.2.1 词语级\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "# 4.2.2 多词语级\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2, 3), max_features=5000)\n",
    "# 4.2.3 词性级\n",
    "tfidf_vect_char = TfidfVectorizer(analyzer='char', ngram_range=(2, 3), max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "951e71c1-f4ff-436c-918b-71d4fc4c1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拟合向量化器并转换文本数据\n",
    "xtrain_tfidf = tfidf_vect.fit_transform(train_data)\n",
    "xtest_tfidf = tfidf_vect.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebd9b20e-5dbe-4912-9e3a-5f6297352c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用转换后的特征向量训练一个机器学习模型\n",
    "from sklearn import naive_bayes\n",
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(xtrain_tfidf, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5690bb30-c3cd-4460-88b9-c5fa7159c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估模型性能\n",
    "# from sklearn import metrics\n",
    "predictions = model.predict(xtest_tfidf)\n",
    "accuracy = metrics.accuracy_score(test_label, predictions)\n",
    "precision = metrics.precision_score(test_label, predictions, average='weighted')\n",
    "recall = metrics.recall_score(test_label, predictions, average='weighted')\n",
    "f1_score = metrics.f1_score(test_label, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b3da3cf-65ad-4ec2-89c9-d9cc61e69685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulNB, Count Vectors:  0.8649164677804296 0.8399602089688345 0.8649164677804296 0.8443554097250083\n"
     ]
    }
   ],
   "source": [
    "# 打印性能指标\n",
    "print(\"MulNB, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e9c0766-fce8-42ac-bd46-960392ff3537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernliNB, Count Vectors:  0.8066295412357465 0.8442659836531052 0.8066295412357465 0.8143012520758793\n"
     ]
    }
   ],
   "source": [
    "model = naive_bayes.BernoulliNB()\n",
    "model.fit(xtrain_tfidf, train_label)\n",
    "\n",
    "predictions = model.predict(xtest_tfidf)\n",
    "accuracy = metrics.accuracy_score(test_label, predictions)\n",
    "precision = metrics.precision_score(test_label, predictions, average='weighted')\n",
    "recall = metrics.recall_score(test_label, predictions, average='weighted')\n",
    "f1_score = metrics.f1_score(test_label, predictions, average='weighted')\n",
    "\n",
    "print(\"BernliNB, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "589ec4a7-561f-4da5-a26c-b46e085a5e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC, Count Vectors:  0.9160434897905065 0.9164114666808467 0.9160434897905065 0.9020550646396233\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(xtrain_tfidf, train_label)\n",
    "\n",
    "predictions = model.predict(xtest_tfidf)\n",
    "accuracy = metrics.accuracy_score(test_label, predictions)\n",
    "precision = metrics.precision_score(test_label, predictions, average='weighted')\n",
    "recall = metrics.recall_score(test_label, predictions, average='weighted')\n",
    "f1_score = metrics.f1_score(test_label, predictions, average='weighted')\n",
    "\n",
    "print(\"SVM, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d632aaee-b959-47ca-908a-d79a74ab2226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFCF, Count Vectors:  0.9153540175019889 0.9128392342309883 0.9153540175019889 0.902828653831452\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier()\n",
    "model.fit(xtrain_tfidf, train_label)\n",
    "\n",
    "predictions = model.predict(xtest_tfidf)\n",
    "accuracy = metrics.accuracy_score(test_label, predictions)\n",
    "precision = metrics.precision_score(test_label, predictions, average='weighted')\n",
    "recall = metrics.recall_score(test_label, predictions, average='weighted')\n",
    "f1_score = metrics.f1_score(test_label, predictions, average='weighted')\n",
    "\n",
    "print(\"RFCF, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aac400ec-d052-43e3-8e02-2cd5709bace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\envs\\py38\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] 系统找不到指定的文件。\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\ANACONDA\\envs\\py38\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 199, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\ANACONDA\\envs\\py38\\lib\\subprocess.py\", line 493, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\ANACONDA\\envs\\py38\\lib\\subprocess.py\", line 858, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\ANACONDA\\envs\\py38\\lib\\subprocess.py\", line 1327, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN, Count Vectors:  0.8727128082736675 0.8740452941697239 0.8727128082736675 0.8635954888856779\n"
     ]
    }
   ],
   "source": [
    "model = neighbors.KNeighborsClassifier()\n",
    "model.fit(xtrain_tfidf, train_label)\n",
    "\n",
    "predictions = model.predict(xtest_tfidf)\n",
    "accuracy = metrics.accuracy_score(test_label, predictions)\n",
    "precision = metrics.precision_score(test_label, predictions, average='weighted')\n",
    "recall = metrics.recall_score(test_label, predictions, average='weighted')\n",
    "f1_score = metrics.f1_score(test_label, predictions, average='weighted')\n",
    "\n",
    "print(\"KNN, Count Vectors: \", accuracy, precision, recall, f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38kernel",
   "language": "python",
   "name": "py38-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
